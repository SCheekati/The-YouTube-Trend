{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.fc6 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "OnnxExporterError",
     "evalue": "Module onnx is not installed!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cheek\\miniconda3\\lib\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:219\u001b[0m, in \u001b[0;36m_add_onnxscript_fn\u001b[1;34m(model_bytes, custom_opsets)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m dummy_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m300\u001b[39m)\n\u001b[0;32m      7\u001b[0m onnx_filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimple_nn.onnx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(model, dummy_input, onnx_filename, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, input_names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m], output_names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\cheek\\miniconda3\\lib\\site-packages\\torch\\onnx\\utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[0;32m    190\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m     _export(\n\u001b[0;32m    507\u001b[0m         model,\n\u001b[0;32m    508\u001b[0m         args,\n\u001b[0;32m    509\u001b[0m         f,\n\u001b[0;32m    510\u001b[0m         export_params,\n\u001b[0;32m    511\u001b[0m         verbose,\n\u001b[0;32m    512\u001b[0m         training,\n\u001b[0;32m    513\u001b[0m         input_names,\n\u001b[0;32m    514\u001b[0m         output_names,\n\u001b[0;32m    515\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[0;32m    516\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[0;32m    517\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[0;32m    518\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[0;32m    519\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[0;32m    520\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[0;32m    521\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[0;32m    522\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cheek\\miniconda3\\lib\\site-packages\\torch\\onnx\\utils.py:1620\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[0;32m   1601\u001b[0m     (\n\u001b[0;32m   1602\u001b[0m         proto,\n\u001b[0;32m   1603\u001b[0m         export_map,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1617\u001b[0m         node_attr_to_name,\n\u001b[0;32m   1618\u001b[0m     )\n\u001b[0;32m   1619\u001b[0m \u001b[39m# insert function_proto into model_proto.\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m proto \u001b[39m=\u001b[39m onnx_proto_utils\u001b[39m.\u001b[39;49m_add_onnxscript_fn(\n\u001b[0;32m   1621\u001b[0m     proto,\n\u001b[0;32m   1622\u001b[0m     custom_opsets,\n\u001b[0;32m   1623\u001b[0m )\n\u001b[0;32m   1624\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m   1625\u001b[0m     torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mExported graph: \u001b[39m\u001b[39m\"\u001b[39m, graph)\n",
      "File \u001b[1;32mc:\\Users\\cheek\\miniconda3\\lib\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:221\u001b[0m, in \u001b[0;36m_add_onnxscript_fn\u001b[1;34m(model_bytes, custom_opsets)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mOnnxExporterError(\u001b[39m\"\u001b[39m\u001b[39mModule onnx is not installed!\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39m# For > 2GB model, onnx.load_fromstring would fail. However, because\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39m# in _export_onnx, the tensors should be saved separately if the proto\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m# size > 2GB, and if it for some reason did not, the model would fail on\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m# serialization anyway in terms of the protobuf limitation. So we don't\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m# need to worry about > 2GB model getting here.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m model_proto \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload_from_string(model_bytes)\n",
      "\u001b[1;31mOnnxExporterError\u001b[0m: Module onnx is not installed!"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "model = SimpleNN(300, 1)\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 300)\n",
    "onnx_filename = \"simple_nn.onnx\"\n",
    "\n",
    "torch.onnx.export(model, dummy_input, onnx_filename, verbose=True, input_names=[\"input\"], output_names=[\"output\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
