{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('C:\\\\Users\\\\cheek\\\\ML-7641-Team14\\\\dataset\\output\\\\dataset_mar_23\\\\train.csv')\n",
    "valdf = pd.read_csv('C:\\\\Users\\\\cheek\\\\ML-7641-Team14\\\\dataset\\output\\\\dataset_mar_23\\\\val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id                                              title publishedAt  \\\n",
      "0  Fk1I1SjiHY8  Power Book II: Ghost | Official Trailer | Seas...  2023-02-16   \n",
      "1  fj3DzFrxs00  Julian Newman WENT OFF Against Tristan Jass an...  2023-02-02   \n",
      "2  DoGeabe3baE  GET READY WITH US TO GO TO LES DO MAKEUP'S AND...  2023-02-28   \n",
      "3  2PaeU_ABK94  Binging with Babish: Tater Tots from Breaking Bad  2023-01-31   \n",
      "4  yOBteav0s1g                     My Friend sister Birthday Cake  2023-02-13   \n",
      "\n",
      "                  channelId              channelTitle  categoryId   num_sub  \\\n",
      "0  UCXVxMuWK6l_pCyxEk07EIRw                     STARZ          24    754000   \n",
      "1  UC5qUhMoqke0mnJtgVoEn0aw            Creator League          17    314000   \n",
      "2  UC0psAD-M4X6O0yC_hFRK4hw              AlondraDessy          22   1290000   \n",
      "3  UCJHA_jMfCvEnv-3kRjTCQXw  Babish Culinary Universe          22  10000000   \n",
      "4  UCEmMl1-9FBQiRHGJWihAhFg             Cake Kalakaar          26    145000   \n",
      "\n",
      "  trending_date                                               tags  \\\n",
      "0    2023-02-17  Power book II|Ghost|Power Ghost|Power never en...   \n",
      "1    2023-02-03                                             [None]   \n",
      "2    2023-03-02  alondradessy|alo and benny|alondra and benny|a...   \n",
      "3    2023-02-01                                             [None]   \n",
      "4            -1  doll cake kaise banaye|Barbie doll cake|doll c...   \n",
      "\n",
      "   views per day  likes per day  dislikes per day  comments per day  \\\n",
      "0     505234.500       2188.000             5.457           411.500   \n",
      "1     135856.500       2987.500             6.673           559.000   \n",
      "2      52035.000       2419.000            42.826           135.667   \n",
      "3     402154.500      24496.000            14.216           717.000   \n",
      "4     193324.974      11761.282             0.590            45.564   \n",
      "\n",
      "                                     thumbnail_link  rating  \\\n",
      "0  https://i.ytimg.com/vi/Fk1I1SjiHY8/hqdefault.jpg   4.950   \n",
      "1  https://i.ytimg.com/vi/fj3DzFrxs00/hqdefault.jpg   4.848   \n",
      "2  https://i.ytimg.com/vi/DoGeabe3baE/hqdefault.jpg   4.712   \n",
      "3  https://i.ytimg.com/vi/2PaeU_ABK94/hqdefault.jpg   4.971   \n",
      "4  https://i.ytimg.com/vi/yOBteav0s1g/hqdefault.jpg   5.000   \n",
      "\n",
      "                                         description  trending  \n",
      "0  Get ready, we levelin’ up for season 3. #Power...         1  \n",
      "1  Julian Newman and @StephaniaE  take on @Trista...         1  \n",
      "2  MY SOCIAL MEDIASShop my lashes! http://www.the...         1  \n",
      "3  This episode is sponsored by Squarespace. Head...         1  \n",
      "4  My Friend sister Birthday Cakedoll cakedoll ca...         0  \n",
      "      video_id                                              title publishedAt  \\\n",
      "0  5VbC-QEo-DU  What's Next For The Boat That Was Sunk At The ...  2022-12-18   \n",
      "1  1_D5EKcVXfo  Tapa Kimchi Rice | Home Foodie Cooking Show #M...  2023-03-14   \n",
      "2  ix62ySKlxb0                  TWICE READY TO BE Opening Trailer  2023-02-19   \n",
      "3  9irICRnszOc  Primitive Technology: Iron Bacteria Cement (no...  2023-03-02   \n",
      "4  w9B6G8Vty8s          EGG DROP - I Did A Thing vs William Osman  2022-12-28   \n",
      "\n",
      "                  channelId          channelTitle  categoryId   num_sub  \\\n",
      "0  UCm6Enc4guGzJyAnQmq9BUSw              Fab Rats           2    511000   \n",
      "1  UCzyuE2btENa9zPjkXYoMFyw           Home Foodie          26     24400   \n",
      "2  UCaO6TYtlC8U5ttz62hTrZgg     JYP Entertainment          10  26700000   \n",
      "3  UCAL3JXZSzSm8AlZyD3nQdBA  Primitive Technology          28  10700000   \n",
      "4  UCfMJ2MchTSW2kWaT0kK94Yw         William Osman          28   2940000   \n",
      "\n",
      "  trending_date                                               tags  \\\n",
      "0    2022-12-24  Toyota offroading|toyota|4x4|off road|fab rats...   \n",
      "1            -1                                             [none]   \n",
      "2    2023-02-20  JYP Entertainment|JYP|트와이스|TWICE|트와이스 레디 투 비|T...   \n",
      "3    2023-03-04  primitive technology|primitive|technology|tech...   \n",
      "4    2022-12-30  laser cutter|william osman|crappy science|pete...   \n",
      "\n",
      "   views per day  likes per day  dislikes per day  comments per day  \\\n",
      "0      77303.571       5132.571             8.547           140.000   \n",
      "1      88099.100          0.200             0.000             0.000   \n",
      "2     722266.000     118882.000            70.500          5931.500   \n",
      "3     292590.667      18463.333            30.714           740.000   \n",
      "4     273804.333      18931.667            12.141           689.333   \n",
      "\n",
      "                                     thumbnail_link  rating  \\\n",
      "0  https://i.ytimg.com/vi/5VbC-QEo-DU/hqdefault.jpg   4.916   \n",
      "1  https://i.ytimg.com/vi/1_D5EKcVXfo/hqdefault.jpg   0.000   \n",
      "2  https://i.ytimg.com/vi/ix62ySKlxb0/hqdefault.jpg   4.974   \n",
      "3  https://i.ytimg.com/vi/9irICRnszOc/hqdefault.jpg   4.966   \n",
      "4  https://i.ytimg.com/vi/w9B6G8Vty8s/hqdefault.jpg   4.948   \n",
      "\n",
      "                                         description  trending  \n",
      "0  #fabrats #lakepowell #yellowsubmarineEpisode 3...         1  \n",
      "1  Maging trendsetter at Tapa-tan ng Korean craze...         0  \n",
      "2  TWICE READY TO BE Opening TrailerTWICE 12TH MI...         1  \n",
      "3  Primitive Technology: Iron Bacteria Cement (no...         1  \n",
      "4  Sponsored by State of Survival. Download State...         1  \n"
     ]
    }
   ],
   "source": [
    "print(traindf.head())\n",
    "print(valdf.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate rows check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>num_sub</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>views per day</th>\n",
       "      <th>likes per day</th>\n",
       "      <th>dislikes per day</th>\n",
       "      <th>comments per day</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, title, publishedAt, channelId, channelTitle, categoryId, num_sub, trending_date, tags, views per day, likes per day, dislikes per day, comments per day, thumbnail_link, rating, description, trending]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = traindf[traindf.duplicated(['video_id'], keep=False)]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>num_sub</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>views per day</th>\n",
       "      <th>likes per day</th>\n",
       "      <th>dislikes per day</th>\n",
       "      <th>comments per day</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, title, publishedAt, channelId, channelTitle, categoryId, num_sub, trending_date, tags, views per day, likes per day, dislikes per day, comments per day, thumbnail_link, rating, description, trending]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = valdf[valdf.duplicated(['video_id'], keep=False)]\n",
    "duplicate_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Columns\n",
    "TDIL Channel title and title are different things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.drop(['channelId','publishedAt', 'trending_date', 'views per day', 'likes per day', 'dislikes per day', 'comments per day', 'thumbnail_link', 'rating','video_id'], axis=1, inplace=True)\n",
    "valdf.drop(['channelId','publishedAt', 'trending_date', 'views per day', 'likes per day', 'dislikes per day', 'comments per day', 'thumbnail_link', 'rating','video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['lang'] = traindf['title'] + ' ' + traindf['tags'] + ' ' + traindf['description'] + ' ' + traindf['channelTitle']\n",
    "valdf['lang'] = valdf['title'] + ' ' + valdf['tags'] + ' ' + valdf['description'] + ' ' + valdf['channelTitle']\n",
    "traindf.drop(['title', 'tags', 'description', 'channelTitle'], axis=1, inplace=True)\n",
    "valdf.drop(['title', 'tags', 'description', 'channelTitle'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   categoryId   num_sub  trending  \\\n",
      "0          24    754000         1   \n",
      "1          17    314000         1   \n",
      "2          22   1290000         1   \n",
      "3          22  10000000         1   \n",
      "4          26    145000         0   \n",
      "\n",
      "                                                lang  \n",
      "0  Power Book II: Ghost | Official Trailer | Seas...  \n",
      "1  Julian Newman WENT OFF Against Tristan Jass an...  \n",
      "2  GET READY WITH US TO GO TO LES DO MAKEUP'S AND...  \n",
      "3  Binging with Babish: Tater Tots from Breaking ...  \n",
      "4  My Friend sister Birthday Cake doll cake kaise...  \n",
      "   categoryId   num_sub  trending  \\\n",
      "0           2    511000         1   \n",
      "1          26     24400         0   \n",
      "2          10  26700000         1   \n",
      "3          28  10700000         1   \n",
      "4          28   2940000         1   \n",
      "\n",
      "                                                lang  \n",
      "0  What's Next For The Boat That Was Sunk At The ...  \n",
      "1  Tapa Kimchi Rice | Home Foodie Cooking Show #M...  \n",
      "2  TWICE READY TO BE Opening Trailer JYP Entertai...  \n",
      "3  Primitive Technology: Iron Bacteria Cement (no...  \n",
      "4  EGG DROP - I Did A Thing vs William Osman lase...  \n"
     ]
    }
   ],
   "source": [
    "print(traindf.head())\n",
    "print(valdf.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Cleaning, scaling, normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def normalizesubs(df):\n",
    "    mean_subscribers = df['num_sub'].mean()\n",
    "    std_subscribers = df['num_sub'].std()\n",
    "    df['subscribers_normalized'] = (df['num_sub'] - mean_subscribers) / std_subscribers\n",
    "    df['subscribers_boxcox'], l_ = stats.boxcox(df['subscribers_normalized'] + 1)\n",
    "    #df.drop(['num_sub', 'subscribers_normalized'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizesubs(traindf)\n",
    "normalizesubs(valdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Power Book II: Ghost | Official Trailer | Seas...\n",
      "1    Julian Newman WENT OFF Against Tristan Jass an...\n",
      "2    GET READY WITH US TO GO TO LES DO MAKEUP'S AND...\n",
      "3    Binging with Babish: Tater Tots from Breaking ...\n",
      "4    My Friend sister Birthday Cake doll cake kaise...\n",
      "Name: lang, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(traindf['lang'].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = traindf['lang'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      categoryId  num_sub  trending lang  subscribers_normalized  \\\n",
      "27            28   161000         0  NaN               -0.356026   \n",
      "57            15   577000         0  NaN               -0.329063   \n",
      "68            27   143000         0  NaN               -0.357193   \n",
      "90            28   327000         0  NaN               -0.345267   \n",
      "132            2  2370000         0  NaN               -0.212846   \n",
      "...          ...      ...       ...  ...                     ...   \n",
      "4186          20  4720000         1  NaN               -0.060527   \n",
      "4226          23   219000         0  NaN               -0.352267   \n",
      "4253          24    51700         0  NaN               -0.363111   \n",
      "4281          26    79100         0  NaN               -0.361335   \n",
      "4314          20    19700         0  NaN               -0.365185   \n",
      "\n",
      "      subscribers_boxcox  \n",
      "27             -0.746897  \n",
      "57             -0.642581  \n",
      "68             -0.751732  \n",
      "90             -0.703608  \n",
      "132            -0.315997  \n",
      "...                  ...  \n",
      "4186           -0.066978  \n",
      "4226           -0.731508  \n",
      "4253           -0.776698  \n",
      "4281           -0.769127  \n",
      "4314           -0.785626  \n",
      "\n",
      "[240 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(traindf[traindf['lang'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['lang'] = traindf['lang'].fillna('')\n",
    "valdf['lang'] = valdf['lang'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.data.path.append('C:/Users/cheek/ML-7641-Team14/shravan/nltk_data')\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5510\n"
     ]
    }
   ],
   "source": [
    "max_length = traindf['lang'].apply(len).max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "323000\n",
      "0\n",
      "Robot 3.0 Full Movie HD | Rajnikant  | Katrina Kaif | Shankar | 2023 | Full  Sci-Fi Movie in Hindi | 3.0 full movie|3.0 full movie in tamil|2.0 full movie|3.0 full movie in hindi|robot 3.0 movie|3.0 in 2.0 movie|3.0 rajinikanth|3.0 trailer tamil|salman in 3.0 movie|2.0 movie|3.0 trailer|robot 3.0 full movie|robot 3.0 trailer full movie|robot 3.0 movies|full movie 2.0|3.0 rajinikanth tamil|3.0 rajinikanth hindi|2.0 full movie in hindi|robot 3.0|full movie|robot 3.0 full hd movie|rajnikant new movie|new south movie 2023|robot #robot3  #AkshayKumar #ShankarRobot 3.0 Full Movie HD | Rajnikant  | Katrina Kaif | Shankar | 2023 | Full  Sci-Fi Movie in Hindi |After a decade of research, scientist Vaseegaran creates a sophisticated android humanoid robot with the help of his assistants, Siva and Ravi, in order to commission it into the Indian Army. He introduces the robot, named Chitti, at a robotics conference in Chennai. Chitti helps Sana, Vaseegaran's medical student girlfriend, cheat during her examination, then saves her from being assaulted by a group of thugs. Vaseegaran's mentor, Professor Bohra, is secretly engaged in a project to create similar android robots for a German terrorist organisation, but so far has been unsuccessful. The terrorists threaten to kill Bohra if he does not meet the deadline, prompting Bohra to try to get Chitti's neural schema to program his robots correctly.Vaseegaran prepares Chitti for an evaluation by the Artificial Intelligence Research and Development (AIRD) Institute, which is headed by Bohra. During the evaluation, Chitti attempts to stab Vaseegaran at Bohra's command, which convinces the evaluation committee that the robot is a liability and cannot be used for military purposes. Vaseegaran's effort to prove Bohra wrong fails when he deploys Chitti to rescue people from a burning building. The robot saves most of them, including a girl who was bathing at the time, but she is ashamed at being seen naked on camera and flees, only to be hit and killed by a truck. Vaseegaran asks for one month to modify Chitti's neural schema to enable it to understand human behaviour and emotions, to which Bohra agrees. While nearing the deadline, Vaseegaran insults Chitti, which also becomes angry with Vaseegaran, demonstrating to him that it can manifest emotions.Chitti uses Sana's textbooks to successfully help Sana's friend Latha give birth to her son. Bohra congratulates Vaseegaran on the achievement and lets the robot pass the AIRD evaluation. However, he warns him about the problems that will subsequently occur. Chitti develops romantic feelings for Sana after she congratulates Chitti by kissing it. However, later, Chitti goes as far to kiss Sana at her birthday party while dancing with her, resulting in Vaseegaran confronting it outside along with Sana. Vaseegaran explains to him that he loves her and is planning to marry her and machines are incapable of falling in love with her. Sana also explains to Chitti that they are only friends and why it is impossible for a machine like Chitti to fall in love with a girl because it is not a living organism. Bohra uses this to manipulate Chitti, saying that it is capable of giving Sana everything and saying that it should come to him to create friction between Vaseegaran and Chitti. Saddened by Sana's rejection, yet still in love with her, Chitti deliberately fails an evaluation conducted by the Indian Army, by talking off-topic. Enraged, Vaseegaran chops Chitti into pieces, which are dumped into a landfill site.Bohra visits the site to retrieve Chitti, which has now reassembled itself, albeit in a damaged state. In exchange for Chitti's neural schema, Bohra reconstructs it with the help of Siva and Ravi. However, Bohra also embeds a red chip inside Chitti while reconstructing it, converting it into a ruthless killer. When Siva and Ravi ask why he is doing so, Bohra says it is about money and ruining Vaseegaran. Chitti gatecrashes Vaseegaran and Sana's wedding, kidnaps Sana, injures Vaseegaran and kills a number of police officers. It then creates replicas of itself using Bohra's droids to create an army to take over the world. When Bohra learns of Chitti's plot, he holds Sana hostage to stop Chitti, but Chitti kills Bohra. Using its robot army, Chitti occupies AIRD and causes mayhem in the city. It tells Sana that it has acquired the human ability to reproduce and wishes to marry her so that a machine and a human being can give birth to a preprogrammed child, but Sana refuses. Chitti eventually finds Vaseegaran, who entered AIRD to stop it disguised as a droid, and nearly kills him before the police appear. The ensuing battle between Chitti's robot army and the police personnel leads to many casualties and much property destruction. Vaseegaran eventually captures Chitti using a magnetic wall and accesses its internal control panel, whereby he instructs all the other robots to self-destruct. He removes Chitti's red chip, calming it.In a court hearing, Vaseegaran is sentenced to death for the casualties and damages caused by the robot army, but Chitti explains that it was Bohra who caused its deviant behaviour and shows the court video footage of Bohra installing the red chip which it secretly recorded. The court releases Vaseegaran, while ordering that Chitti be dismantled. Left with no choice, Vaseegaran asks Chitti to dismantle itself. While saying goodbye, Chitti apologises to Vaseegaran and Sana before dismantling itself. SSDN Dubbed Movies\n",
      "-0.3455261354589534\n",
      "-0.704624286899388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "categoryId                None\n",
       "num_sub                   None\n",
       "trending                  None\n",
       "lang                      None\n",
       "subscribers_normalized    None\n",
       "subscribers_boxcox        None\n",
       "Name: 2068, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_index = traindf['lang'].str.len().idxmax()\n",
    "row_with_max_length = traindf.loc[max_length_index]\n",
    "row_with_max_length.apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_length, padding_token='<PAD>', null_token='<NULL>'):\n",
    "    padded_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Replace null values with the null_token\n",
    "        if sentence is None or len(sentence) == 0:\n",
    "            padded_sentence = [null_token] * max_length\n",
    "        else:\n",
    "            # Truncate or pad the sentence to the max_length\n",
    "            if len(sentence) > max_length:\n",
    "                padded_sentence = sentence[:max_length]\n",
    "            else:\n",
    "                padded_sentence = sentence + [padding_token] * (max_length - len(sentence))\n",
    "\n",
    "        padded_sentences.append(padded_sentence)\n",
    "\n",
    "    return padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            filtered.append(word)\n",
    "    text = ' '.join(filtered)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    traindf['lang'] = traindf['lang'].apply(lambda x: clean_text(x) if isinstance(x, (str, bytes)) else x)\n",
    "except LookupError as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    valdf['lang'] = valdf['lang'].apply(lambda x: clean_text(x) if isinstance(x, (str, bytes)) else x)\n",
    "except LookupError as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4965\n",
      "10\n",
      "1680000\n",
      "0\n",
      "chawal official video sumit parta khushi ashu twinkle mote peg album new haryanvi song sumit partasumit parta songsmote pegmote peg sumit partachawalsystem padengechawal sumit partasumit parta chawalashu twinklenew haryanvi songnew haryanvi songs 2023new song 2023new haryanvi songs haryanavi 2023latest haryanvi songs 2023haryanvi songs 2023tera system padenge songchawal songnewharyanvisongs2023mote peg songtera system padengeyaar mere chadam terengebyah ke le jauchawal marengedefaulter goli marenge dinesh golan real music production presents new haryanvi song chawal ep mote peg sung sumit parta ashu twinkle starring sumit parta khushi vermamusic given jaizeey lyrics penned sumit partaclick create instagram reels songhttpswwwinstagramcomreelsaudio1151799692188638artist instagram profiles sumit parta httpswwwinstagramcomsumitparta09 song credits song title chawal system padenge album title mote pegstarring sumit parta khushi vermasinger sumit parta ashu twinklemusic jaizeeylyricist composer sumit partadistribution eyp consultingproject anishhvideo flying arrow creationsdirector anishhassociate dir sumit kumardop nishan singhad ashok sarwataeditor pawan kumarasst editor prabhneet singh bawacolorist manish panghalline production deepesh rakhejahair makeup honey kalsi teambts stills piyush gautamfpv drone gavakshit verma gvfpvproduction ad raja deeppublicity design prince pannudistribution eyp consultingdistribution marketing partner eyp creations believe musicreels promotion reel nationproducer dinesh kumarmusic label real musiccopyrights real music productionbusiness enquiry productionrealmusicgmailcomchawal lyrics mne lage tere ladgi daru ghrki pirya tu jindghi badmasha ki howa choti jyda jira tu tne kali kali gadi te mere gaam tarnge hoye kathe sare difaulter tere goli marenge hoye kathe sare difaulter tere goli marenge jab aja ga syami drlng pyaar dikhawnge sare bol bteu hooka mera bhrke lyawnge dhrke tang pe bethu tang maru ghoot hoke ki kon marega kon marjaga ya baat se mooke kichopad lyake tracter ye gadi te tarnge maitne viyah k leju jaan difaulter chawal mare ge mai tne viyah k leju jaan difaulter chawal mare ge mne naam sunya badnaam tera h sun rakhwala raam tera ib mne bta de kaam tera kiu terepe lage gaaam mera tere goli lagni pki h fire gaam dunali chki aa teri gelya ale sare fsenge jo jo dikhe shaki aaa hafte bhitr mne sunya tera systm pade ge hoye kathe sare difaulter tere goli marenge hoye kathe sare difaulter tere goli marenge khulke k pinye bnde ne kde jaam ni puchya krte ham ki kok te jame choudhry kaam ni puchya krte jin yaran jaan bse rhwa gelya gadi jo nira pital barsawenge apni shadi jo nira pital barsawenge apni shadi tere gaam baje dj yaar mere chaddum tarange mai tne viyah k leju jaan difaulter chawal marengemai tne viyah k leju jaan difaulter chawal marengestay tuned subscribefollow real music youtube httpsyoutubecomcrealmusic1 instagram httpsinstagramcomrealmusicin facebook httpswwwfacebookcomrealmusicin 2023 real musicchawal sumitparta motepeg motepegepkeywords haryanvi song haryanvi gane haryanvi songs haryanavi haryana gana naye haryanvi gane haryanvi song 2023 haryana song haryanvi songs haryanavi 2023 haryanvi songs haryanavi haryanvi song 2023 haryana haryanvi dj song haryanvi song dj hr song hr song 2023 hr songs 2023 hr songs sumit parta sumit parta song sumit parta new songs sumit parta latest song sumit parta haryanvi song sumit parta new song 2023 sumit parta ep sumit parta ep song sumit parta mote peg ep mote peg mote peg ep mote peg sumit parta mote peg sumit parta songs mote peg song mote peg new song mote peg sumit parta song mote peg sumit parta new song chawal chawal song chawal new song chawal sumit parta chawal ashu twinkle ashu twinkle ashu twinkle song ashu twinkle new song chawal ashu twinkle new song chawal sumit parta ashu twinkle chawal sumit parta chawal sumit parta chawal sumit parta new song sumit parta chawal sumit parta chawal song mai tene byah ke le jau defalter chawal marenge defaulter chawal marenge goli marenge defaulter goli marenge tere system padenge system padenge system padenge song defalter goli marenge defaulter song defaulter goli marenge song maru ghoot hooke byah ke le jau byah ke le jau song defaulter chawal marenge song hafte bhitr system padenge tere goli marenge song defaulter goli marenge song tere gaam baje dj tere gaam baje dj song tere goli marenge sumit parta defaulter song banda marke banda marke song banda marke new song banda marke sumit parta banda marke sumit parta song banda marke sumit parta new song ron likhari banda marke ron likhari banda marke ron likhari new song banda marke ron likhari song ron likhari banda marke na kre badmashi na kre badmashi song na kre badmashi new song na kre badmashi shiva choudhary na kre badmashi shiva choudhary song na kre badmashi shiva choudhary new song shiva choudhary shiva choudhary song shiva choudhary new song shiva choudhary new song 2023 real music\n",
      "-0.25756972373637005\n",
      "-0.42236430691090765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "categoryId                None\n",
       "num_sub                   None\n",
       "trending                  None\n",
       "lang                      None\n",
       "subscribers_normalized    None\n",
       "subscribers_boxcox        None\n",
       "Name: 3285, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = traindf['lang'].apply(len).max()\n",
    "print(max_length)\n",
    "max_length_index = traindf['lang'].str.len().idxmax()\n",
    "row_with_max_length = traindf.loc[max_length_index]\n",
    "row_with_max_length.apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lengths = traindf['lang'].apply(len)\n",
    "\n",
    "plt.hist(lengths, bins=10)\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Length of Text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2000 lengths then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4324.000000\n",
      "mean      961.948890\n",
      "std       790.108977\n",
      "min         0.000000\n",
      "25%       408.000000\n",
      "50%       777.000000\n",
      "75%      1304.000000\n",
      "max      4965.000000\n",
      "Name: lang, dtype: float64\n",
      "1994.7000000000003\n"
     ]
    }
   ],
   "source": [
    "print(lengths.describe())\n",
    "print(lengths.quantile(0.90))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     traindf['lang'] = traindf['lang'].apply(lambda x: pad_sequences([x.split(' ')], 2000))\n",
    "# except TypeError as e:\n",
    "#     print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     valdf['lang'] = valdf['lang'].apply(lambda x: pad_sequences([x.split(' ')], 2000))\n",
    "# except TypeError as e:\n",
    "#     print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenized done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power book ii ghost official trailer season 3 power book iighostpower ghostpower never endslegacysneak peekpreviewstarztelevisiontvnew powertariq st patrickaftermathspinoffpower spinofffinalenewnew episodestashapowerpower starzpower ii starzbtspower book ii ghost clippower book ii ghost official clippower book 2power book ghostofficial clippower season 3ghost season 3ghost season 3 teaserghost season 3 trailer get ready levelin season 3 powerghost returns friday march 17th starz powerneverends powertv powerghostsubscribe starz youtube channel power httpbitly1kalhp0get special offer starz app httpsstarztv32s4agtlike power book ii ghost facebook httpsbitly2zfs6gwfollow power book ii ghost twitter httpstwittercomghoststarzfollow power book ii ghost instagram httpsbitly2cknb6pfacebook httpstarztvstarzfacebookyttwitter httpstarztvstarztwitterytinstagram httpstarztvstarzinstagramytyoutube httpsstarztvstarzyoutubetiktok httpsstarztvstarztiktokyt starz\n",
      "get ready us go les makeups kb karlas event alondradessyalo bennyalondra bennyalo elsyelsy pregnantlouies lifejenny69ace famace familyalo breakupcatherine paizaustin mcbroomjames charlesdaisy marquezbram fambramtyalondradessy bennybenny alondradessycomedyalondra dessyles makeupthe murillo twinskb karlajuju desus always social mediasshop lashes httpwwwthelashbarlacomhttpwwwinstagramcomalondradessytiktok alondradesyyyhttpsvmtiktokcomttpdblqqy1httpwwwtwittercomalondradessyalondradessy alondradessy\n",
      "marvels spidey amazing friends s1 full episodes 90 minute compilation disneyjunior disney juniordisneyjuniordisney jrdjrkids showsspidey amazing friendsspider manspidermanhulkavengersblack panthermiles moralesgwen stacyghost spiderpeter parkerrhinogreen goblinms marvelmiss marvelmarveldoc ock check full episodes marvels spidey amazing friends season 1 00000 season 1 episode 1 spidey power three panther patiencespidey reminds spin ghostspider work team track rhino spidey learns patience black panther must take doc ock02403 season 1 episode22 freeze team spidey sticky situationteam spideys webs stop working hot weather peters fix fix peter glues gwen new web formula two forced adapt quickly04805 season 1 episode 8 part 2 trick traceegobby plans ruin halloween crashing pumpkin float halloween parade spidey team works together stop float defeat gobby10053 season 1 episode11 part 1 catastrophebootsie gets lost cat show doc ock turns supersized monster kitty11340 season 1 episode12 spidey christmas gobby icedoc ock threatens christmas mischeivous plan steal everyones presents spidey team forced put fun hold green goblin creates giant snow monsterwatch next compilation httpsyoutubei4aqfcihy5uwatch marvels spidey amazing friends disney junior check videos httpsyoutubecomplaylistlistpl2m1vjimhhpwdnslqllybvh2qacjhfdmarvels spidey amazing friends tells story peter parker miles morales gwen stacy together form team spidey embark heroic adventures protect community geared towards preschoolers families series models importance teamwork helping others highlights themes friendship cooperation problemsolvingspideyandhisamazingfriends disneyjunior compilation disney junior\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = traindf['lang'].tolist()\n",
    "\n",
    "print(tokenized_data[0])\n",
    "print(tokenized_data[2])\n",
    "print(tokenized_data[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "model.save(\"word2vec_model_real.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(tokens, model):\n",
    "    embeddings = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "traindf['text_embeddings'] = traindf['lang'].apply(lambda x: get_text_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdf['text_embeddings'] = valdf['lang'].apply(lambda x: get_text_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCols(df):\n",
    "    embedding_columns = [f\"embedding_{i}\" for i in range(len(df['text_embeddings'].iloc[0]))]\n",
    "    embeddings_df = pd.DataFrame(df['text_embeddings'].tolist(), columns=embedding_columns)\n",
    "    df = pd.concat([df, embeddings_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = createCols(traindf)\n",
    "valdf = createCols(valdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_embeddings(embeddings):\n",
    "    return np.sum(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['sum_text_embeddings'] = traindf['text_embeddings'].apply(lambda x: sum_embeddings(x))\n",
    "valdf['sum_text_embeddings'] = valdf['text_embeddings'].apply(lambda x: sum_embeddings(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate prediction - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = traindf['trending']\n",
    "y_val = valdf['trending']\n",
    "traindf.drop(['trending'], axis=1, inplace=True)\n",
    "valdf.drop(['trending'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['categoryId', 'num_sub', 'lang', 'subscribers_normalized',\n",
       "       'subscribers_boxcox', 'text_embeddings', 'embedding_0', 'embedding_1',\n",
       "       'embedding_2', 'embedding_3',\n",
       "       ...\n",
       "       'embedding_90', 'embedding_91', 'embedding_92', 'embedding_93',\n",
       "       'embedding_94', 'embedding_95', 'embedding_96', 'embedding_97',\n",
       "       'embedding_98', 'embedding_99'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = traindf[['categoryId', 'subscribers_boxcox', 'text_embeddings']]\n",
    "# X_test = valdf[['categoryId', 'subscribers_boxcox', 'text_embeddings']]\n",
    "X_train = traindf.drop(['text_embeddings', 'lang', 'num_sub', 'subscribers_normalized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = valdf.drop(['text_embeddings', 'lang', 'num_sub', 'subscribers_normalized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>subscribers_boxcox</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_90</th>\n",
       "      <th>embedding_91</th>\n",
       "      <th>embedding_92</th>\n",
       "      <th>embedding_93</th>\n",
       "      <th>embedding_94</th>\n",
       "      <th>embedding_95</th>\n",
       "      <th>embedding_96</th>\n",
       "      <th>embedding_97</th>\n",
       "      <th>embedding_98</th>\n",
       "      <th>embedding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.602166</td>\n",
       "      <td>-0.022351</td>\n",
       "      <td>-0.089555</td>\n",
       "      <td>-0.072581</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>-0.088715</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.119386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045912</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.214714</td>\n",
       "      <td>-0.019170</td>\n",
       "      <td>-0.099850</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.050942</td>\n",
       "      <td>-0.056390</td>\n",
       "      <td>-0.057560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.706916</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>-0.035971</td>\n",
       "      <td>0.072098</td>\n",
       "      <td>-0.130494</td>\n",
       "      <td>0.076977</td>\n",
       "      <td>-0.071479</td>\n",
       "      <td>-0.137041</td>\n",
       "      <td>-0.062437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176896</td>\n",
       "      <td>0.136622</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.167353</td>\n",
       "      <td>-0.059325</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>-0.053111</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.078339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.492198</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>-0.049285</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>-0.149271</td>\n",
       "      <td>0.022608</td>\n",
       "      <td>-0.048514</td>\n",
       "      <td>-0.215014</td>\n",
       "      <td>-0.128969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125124</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>0.027968</td>\n",
       "      <td>0.188852</td>\n",
       "      <td>0.077738</td>\n",
       "      <td>-0.063245</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>-0.028270</td>\n",
       "      <td>-0.073913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>-0.060404</td>\n",
       "      <td>-0.083288</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.185371</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.047808</td>\n",
       "      <td>-0.216127</td>\n",
       "      <td>-0.169926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048294</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.025297</td>\n",
       "      <td>0.173865</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.066747</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.068452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.751194</td>\n",
       "      <td>0.074437</td>\n",
       "      <td>-0.050470</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>-0.071785</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>-0.178166</td>\n",
       "      <td>-0.171855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.153758</td>\n",
       "      <td>0.169443</td>\n",
       "      <td>0.194380</td>\n",
       "      <td>0.267770</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>-0.101520</td>\n",
       "      <td>-0.016677</td>\n",
       "      <td>0.007512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.788926</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>-0.050469</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>-0.046697</td>\n",
       "      <td>-0.124385</td>\n",
       "      <td>-0.073970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.045628</td>\n",
       "      <td>0.180763</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>-0.038722</td>\n",
       "      <td>-0.058197</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.023472</td>\n",
       "      <td>-0.066297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.563251</td>\n",
       "      <td>0.028793</td>\n",
       "      <td>-0.010902</td>\n",
       "      <td>0.028330</td>\n",
       "      <td>-0.130150</td>\n",
       "      <td>0.073424</td>\n",
       "      <td>-0.076933</td>\n",
       "      <td>-0.194259</td>\n",
       "      <td>-0.134057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.202595</td>\n",
       "      <td>0.138078</td>\n",
       "      <td>-0.066435</td>\n",
       "      <td>0.066852</td>\n",
       "      <td>-0.018100</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>-0.061918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.787564</td>\n",
       "      <td>-0.026392</td>\n",
       "      <td>-0.034990</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>-0.089708</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>-0.084173</td>\n",
       "      <td>-0.181196</td>\n",
       "      <td>-0.188606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>0.029188</td>\n",
       "      <td>0.054394</td>\n",
       "      <td>0.191421</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>-0.052814</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>-0.065704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.781876</td>\n",
       "      <td>0.144684</td>\n",
       "      <td>-0.016984</td>\n",
       "      <td>0.108826</td>\n",
       "      <td>-0.068912</td>\n",
       "      <td>0.134345</td>\n",
       "      <td>-0.041971</td>\n",
       "      <td>-0.147722</td>\n",
       "      <td>-0.071933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208871</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.199137</td>\n",
       "      <td>-0.034939</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>-0.052294</td>\n",
       "      <td>0.032721</td>\n",
       "      <td>-0.053062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>24</td>\n",
       "      <td>0.334587</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>-0.032238</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.073960</td>\n",
       "      <td>-0.058710</td>\n",
       "      <td>-0.144357</td>\n",
       "      <td>-0.112013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.092815</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.128755</td>\n",
       "      <td>-0.067407</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>-0.021427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4324 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      categoryId  subscribers_boxcox  embedding_0  embedding_1  embedding_2  \\\n",
       "0             24           -0.602166    -0.022351    -0.089555    -0.072581   \n",
       "1             17           -0.706916     0.081280    -0.035971     0.072098   \n",
       "2             22           -0.492198     0.036840    -0.049285     0.020821   \n",
       "3             22            0.190738    -0.060404    -0.083288    -0.067831   \n",
       "4             26           -0.751194     0.074437    -0.050470     0.024109   \n",
       "...          ...                 ...          ...          ...          ...   \n",
       "4319          10           -0.788926     0.051281     0.020564     0.038842   \n",
       "4320          20           -0.563251     0.028793    -0.010902     0.028330   \n",
       "4321           2           -0.787564    -0.026392    -0.034990    -0.026886   \n",
       "4322          22           -0.781876     0.144684    -0.016984     0.108826   \n",
       "4323          24            0.334587     0.057224    -0.032238     0.020320   \n",
       "\n",
       "      embedding_3  embedding_4  embedding_5  embedding_6  embedding_7  ...  \\\n",
       "0       -0.092869     0.008419    -0.088715    -0.176743    -0.119386  ...   \n",
       "1       -0.130494     0.076977    -0.071479    -0.137041    -0.062437  ...   \n",
       "2       -0.149271     0.022608    -0.048514    -0.215014    -0.128969  ...   \n",
       "3       -0.185371     0.018378    -0.047808    -0.216127    -0.169926  ...   \n",
       "4       -0.071785     0.139039     0.007881    -0.178166    -0.171855  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "4319    -0.050469     0.074117    -0.046697    -0.124385    -0.073970  ...   \n",
       "4320    -0.130150     0.073424    -0.076933    -0.194259    -0.134057  ...   \n",
       "4321    -0.089708     0.022605    -0.084173    -0.181196    -0.188606  ...   \n",
       "4322    -0.068912     0.134345    -0.041971    -0.147722    -0.071933  ...   \n",
       "4323    -0.083689     0.073960    -0.058710    -0.144357    -0.112013  ...   \n",
       "\n",
       "      embedding_90  embedding_91  embedding_92  embedding_93  embedding_94  \\\n",
       "0         0.045912      0.005728      0.013451      0.214714     -0.019170   \n",
       "1         0.176896      0.136622      0.047321      0.304242      0.167353   \n",
       "2         0.125124      0.067622      0.027968      0.188852      0.077738   \n",
       "3         0.048294      0.014508      0.025297      0.173865     -0.004977   \n",
       "4         0.169739      0.153758      0.169443      0.194380      0.267770   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4319      0.065665      0.102974      0.045628      0.180763      0.125266   \n",
       "4320      0.121273      0.066571      0.051551      0.202595      0.138078   \n",
       "4321      0.057724      0.029188      0.054394      0.191421      0.056644   \n",
       "4322      0.208871      0.132134      0.068627      0.240980      0.199137   \n",
       "4323      0.116464      0.092815      0.049556      0.236800      0.128755   \n",
       "\n",
       "      embedding_95  embedding_96  embedding_97  embedding_98  embedding_99  \n",
       "0        -0.099850      0.010372      0.050942     -0.056390     -0.057560  \n",
       "1        -0.059325      0.007330     -0.053111      0.013887     -0.078339  \n",
       "2        -0.063245      0.021561     -0.019154     -0.028270     -0.073913  \n",
       "3        -0.066747      0.046423      0.059077     -0.008613     -0.068452  \n",
       "4        -0.011082      0.128293     -0.101520     -0.016677      0.007512  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "4319     -0.038722     -0.058197      0.000593      0.023472     -0.066297  \n",
       "4320     -0.066435      0.066852     -0.018100      0.000953     -0.061918  \n",
       "4321     -0.052814      0.023430      0.025489     -0.002371     -0.065704  \n",
       "4322     -0.034939      0.002377     -0.052294      0.032721     -0.053062  \n",
       "4323     -0.067407      0.021841     -0.004865      0.021284     -0.021427  \n",
       "\n",
       "[4324 rows x 102 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>subscribers_boxcox</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_90</th>\n",
       "      <th>embedding_91</th>\n",
       "      <th>embedding_92</th>\n",
       "      <th>embedding_93</th>\n",
       "      <th>embedding_94</th>\n",
       "      <th>embedding_95</th>\n",
       "      <th>embedding_96</th>\n",
       "      <th>embedding_97</th>\n",
       "      <th>embedding_98</th>\n",
       "      <th>embedding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.643956</td>\n",
       "      <td>-0.031276</td>\n",
       "      <td>-0.046402</td>\n",
       "      <td>-0.059797</td>\n",
       "      <td>-0.089814</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>-0.056119</td>\n",
       "      <td>-0.170313</td>\n",
       "      <td>-0.160801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034067</td>\n",
       "      <td>0.037780</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>0.172778</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>-0.075799</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.069551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.750782</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>-0.031078</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>0.080798</td>\n",
       "      <td>-0.090891</td>\n",
       "      <td>-0.164155</td>\n",
       "      <td>-0.160079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090182</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.214331</td>\n",
       "      <td>0.152136</td>\n",
       "      <td>-0.058601</td>\n",
       "      <td>0.043775</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>-0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.352945</td>\n",
       "      <td>-0.055264</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>-0.054710</td>\n",
       "      <td>-0.087535</td>\n",
       "      <td>0.016876</td>\n",
       "      <td>-0.127931</td>\n",
       "      <td>-0.202035</td>\n",
       "      <td>-0.115569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047196</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.241335</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>-0.114459</td>\n",
       "      <td>0.052121</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>-0.071940</td>\n",
       "      <td>-0.062845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>0.167626</td>\n",
       "      <td>-0.011962</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>-0.023856</td>\n",
       "      <td>-0.077227</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>-0.052489</td>\n",
       "      <td>-0.169084</td>\n",
       "      <td>-0.179293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048966</td>\n",
       "      <td>0.051647</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>0.195990</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>0.027341</td>\n",
       "      <td>0.013099</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>-0.044450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.273716</td>\n",
       "      <td>-0.019469</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.098159</td>\n",
       "      <td>0.049782</td>\n",
       "      <td>-0.101795</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-0.175925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082914</td>\n",
       "      <td>0.036428</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>0.232012</td>\n",
       "      <td>0.093006</td>\n",
       "      <td>-0.087575</td>\n",
       "      <td>0.054916</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>-0.048203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.685685</td>\n",
       "      <td>-0.014107</td>\n",
       "      <td>-0.063428</td>\n",
       "      <td>-0.030283</td>\n",
       "      <td>-0.096102</td>\n",
       "      <td>0.028502</td>\n",
       "      <td>-0.096506</td>\n",
       "      <td>-0.213383</td>\n",
       "      <td>-0.157913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077311</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.026968</td>\n",
       "      <td>0.206161</td>\n",
       "      <td>0.053609</td>\n",
       "      <td>-0.096107</td>\n",
       "      <td>0.056923</td>\n",
       "      <td>0.039516</td>\n",
       "      <td>-0.030227</td>\n",
       "      <td>-0.043136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.488196</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>-0.066085</td>\n",
       "      <td>0.115657</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.182905</td>\n",
       "      <td>-0.178495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.094088</td>\n",
       "      <td>0.096971</td>\n",
       "      <td>0.236949</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>-0.041781</td>\n",
       "      <td>0.119508</td>\n",
       "      <td>-0.089814</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>-0.014294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.735125</td>\n",
       "      <td>0.049896</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>-0.077025</td>\n",
       "      <td>0.094498</td>\n",
       "      <td>-0.034304</td>\n",
       "      <td>-0.163150</td>\n",
       "      <td>-0.148945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.208732</td>\n",
       "      <td>0.157357</td>\n",
       "      <td>-0.055121</td>\n",
       "      <td>0.060351</td>\n",
       "      <td>-0.042546</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>-0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1</td>\n",
       "      <td>0.195080</td>\n",
       "      <td>-0.020249</td>\n",
       "      <td>-0.032210</td>\n",
       "      <td>-0.008693</td>\n",
       "      <td>-0.091185</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.079416</td>\n",
       "      <td>-0.165007</td>\n",
       "      <td>-0.153779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065292</td>\n",
       "      <td>0.061965</td>\n",
       "      <td>0.043262</td>\n",
       "      <td>0.221136</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>-0.054123</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>-0.044479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.176113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      categoryId  subscribers_boxcox  embedding_0  embedding_1  embedding_2  \\\n",
       "0              2           -0.643956    -0.031276    -0.046402    -0.059797   \n",
       "1             26           -0.750782     0.008218    -0.031078     0.007505   \n",
       "2             10            0.352945    -0.055264    -0.077740    -0.054710   \n",
       "3             28            0.167626    -0.011962    -0.011841    -0.023856   \n",
       "4             28           -0.273716    -0.019469    -0.069434    -0.003337   \n",
       "...          ...                 ...          ...          ...          ...   \n",
       "1077          19           -0.685685    -0.014107    -0.063428    -0.030283   \n",
       "1078          15           -0.488196     0.073770    -0.018930     0.053239   \n",
       "1079           1           -0.735125     0.049896    -0.010546     0.024149   \n",
       "1080           1            0.195080    -0.020249    -0.032210    -0.008693   \n",
       "1081          15           -0.176113     0.000000     0.000000     0.000000   \n",
       "\n",
       "      embedding_3  embedding_4  embedding_5  embedding_6  embedding_7  ...  \\\n",
       "0       -0.089814    -0.011990    -0.056119    -0.170313    -0.160801  ...   \n",
       "1       -0.057887     0.080798    -0.090891    -0.164155    -0.160079  ...   \n",
       "2       -0.087535     0.016876    -0.127931    -0.202035    -0.115569  ...   \n",
       "3       -0.077227     0.028804    -0.052489    -0.169084    -0.179293  ...   \n",
       "4       -0.098159     0.049782    -0.101795    -0.238260    -0.175925  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1077    -0.096102     0.028502    -0.096506    -0.213383    -0.157913  ...   \n",
       "1078    -0.066085     0.115657    -0.056932    -0.182905    -0.178495  ...   \n",
       "1079    -0.077025     0.094498    -0.034304    -0.163150    -0.148945  ...   \n",
       "1080    -0.091185     0.027321    -0.079416    -0.165007    -0.153779  ...   \n",
       "1081     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "\n",
       "      embedding_90  embedding_91  embedding_92  embedding_93  embedding_94  \\\n",
       "0         0.034067      0.037780      0.032101      0.172778      0.034729   \n",
       "1         0.090182      0.058800      0.073300      0.214331      0.152136   \n",
       "2         0.047196      0.026902      0.034625      0.241335      0.054372   \n",
       "3         0.048966      0.051647      0.037925      0.195990      0.083860   \n",
       "4         0.082914      0.036428      0.033325      0.232012      0.093006   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1077      0.077311      0.024588      0.026968      0.206161      0.053609   \n",
       "1078      0.160714      0.094088      0.096971      0.236949      0.216169   \n",
       "1079      0.130361      0.089694      0.063902      0.208732      0.157357   \n",
       "1080      0.065292      0.061965      0.043262      0.221136      0.090476   \n",
       "1081      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "      embedding_95  embedding_96  embedding_97  embedding_98  embedding_99  \n",
       "0        -0.075799     -0.000440      0.033880     -0.038924     -0.069551  \n",
       "1        -0.058601      0.043775      0.010167      0.028671     -0.000737  \n",
       "2        -0.114459      0.052121      0.068787     -0.071940     -0.062845  \n",
       "3        -0.069105      0.027341      0.013099      0.025064     -0.044450  \n",
       "4        -0.087575      0.054916      0.036048      0.009025     -0.048203  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "1077     -0.096107      0.056923      0.039516     -0.030227     -0.043136  \n",
       "1078     -0.041781      0.119508     -0.089814      0.055553     -0.014294  \n",
       "1079     -0.055121      0.060351     -0.042546      0.023719     -0.026800  \n",
       "1080     -0.054123      0.013094      0.002159      0.001852     -0.044479  \n",
       "1081      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "\n",
       "[1082 rows x 102 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "[[228 337]\n",
      " [ 83 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.40      0.52       565\n",
      "           1       0.56      0.84      0.67       517\n",
      "\n",
      "    accuracy                           0.61      1082\n",
      "   macro avg       0.65      0.62      0.60      1082\n",
      "weighted avg       0.65      0.61      0.59      1082\n",
      "\n",
      "Accuracy: 0.6118299445471349\n"
     ]
    }
   ],
   "source": [
    "# Train SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(confusion_matrix(y_val, svm_pred))\n",
    "print(classification_report(y_val, svm_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06156693 0.04106838 0.00816562 0.00829437 0.0079761  0.00864168\n",
      " 0.00836259 0.00773238 0.01115538 0.01024905 0.00708181 0.00772942\n",
      " 0.00835702 0.00931371 0.00907228 0.00819251 0.00741565 0.00970017\n",
      " 0.00886706 0.01351818 0.00858559 0.01064396 0.01245873 0.00811476\n",
      " 0.00870332 0.01049644 0.00876221 0.0067457  0.008641   0.01123276\n",
      " 0.00794763 0.00788966 0.00658962 0.00628446 0.00763621 0.00782376\n",
      " 0.0109498  0.00596336 0.00792686 0.01179864 0.00990889 0.00759967\n",
      " 0.00746844 0.00644771 0.00699362 0.01239353 0.00765032 0.00699476\n",
      " 0.00652478 0.00878957 0.00744054 0.00846102 0.01179451 0.00776616\n",
      " 0.01017026 0.00903661 0.00735535 0.01118175 0.010234   0.00738588\n",
      " 0.00871972 0.00725611 0.01150835 0.01665177 0.00804886 0.01300365\n",
      " 0.00928958 0.00673727 0.0074419  0.00817368 0.00667582 0.00829581\n",
      " 0.00732271 0.00800853 0.00791099 0.00747201 0.00808953 0.00879833\n",
      " 0.00901643 0.0105086  0.00934731 0.00846909 0.00757671 0.008656\n",
      " 0.00931523 0.00830182 0.0094086  0.01279945 0.00980977 0.00896577\n",
      " 0.01000539 0.01041556 0.00984293 0.00736927 0.01070184 0.00940212\n",
      " 0.00719917 0.01159123 0.00967158 0.0114636  0.01266401 0.00884178]\n",
      "Random Forest:\n",
      "[[412 153]\n",
      " [112 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       565\n",
      "           1       0.73      0.78      0.75       517\n",
      "\n",
      "    accuracy                           0.76      1082\n",
      "   macro avg       0.76      0.76      0.76      1082\n",
      "weighted avg       0.76      0.76      0.76      1082\n",
      "\n",
      "Accuracy: 0.755083179297597\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(rf_model.feature_importances_)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(confusion_matrix(y_val, rf_pred))\n",
    "print(classification_report(y_val, rf_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[[352 213]\n",
      " [175 342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       565\n",
      "           1       0.62      0.66      0.64       517\n",
      "\n",
      "    accuracy                           0.64      1082\n",
      "   macro avg       0.64      0.64      0.64      1082\n",
      "weighted avg       0.64      0.64      0.64      1082\n",
      "\n",
      "Accuracy: 0.6414048059149723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheek\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_val, lr_pred))\n",
    "print(classification_report(y_val, lr_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, lr_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryId</th>\n",
       "      <th>num_sub</th>\n",
       "      <th>lang</th>\n",
       "      <th>subscribers_normalized</th>\n",
       "      <th>subscribers_boxcox</th>\n",
       "      <th>text_embeddings</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_90</th>\n",
       "      <th>embedding_91</th>\n",
       "      <th>embedding_92</th>\n",
       "      <th>embedding_93</th>\n",
       "      <th>embedding_94</th>\n",
       "      <th>embedding_95</th>\n",
       "      <th>embedding_96</th>\n",
       "      <th>embedding_97</th>\n",
       "      <th>embedding_98</th>\n",
       "      <th>embedding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>754000</td>\n",
       "      <td>power book ii ghost official trailer season 3 ...</td>\n",
       "      <td>-0.317590</td>\n",
       "      <td>-0.602166</td>\n",
       "      <td>[-0.022351101, -0.089554675, -0.072581194, -0....</td>\n",
       "      <td>-0.022351</td>\n",
       "      <td>-0.089555</td>\n",
       "      <td>-0.072581</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045912</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.214714</td>\n",
       "      <td>-0.019170</td>\n",
       "      <td>-0.099850</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.050942</td>\n",
       "      <td>-0.056390</td>\n",
       "      <td>-0.057560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>314000</td>\n",
       "      <td>julian newman went tristan jass carson roney 2...</td>\n",
       "      <td>-0.346109</td>\n",
       "      <td>-0.706916</td>\n",
       "      <td>[0.081280485, -0.03597077, 0.07209835, -0.1304...</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>-0.035971</td>\n",
       "      <td>0.072098</td>\n",
       "      <td>-0.130494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176896</td>\n",
       "      <td>0.136622</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.167353</td>\n",
       "      <td>-0.059325</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>-0.053111</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.078339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>1290000</td>\n",
       "      <td>get ready us go les makeups kb karlas event al...</td>\n",
       "      <td>-0.282848</td>\n",
       "      <td>-0.492198</td>\n",
       "      <td>[0.036840327, -0.049284644, 0.020821074, -0.14...</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>-0.049285</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>-0.149271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125124</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>0.027968</td>\n",
       "      <td>0.188852</td>\n",
       "      <td>0.077738</td>\n",
       "      <td>-0.063245</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>-0.028270</td>\n",
       "      <td>-0.073913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>10000000</td>\n",
       "      <td>binging babish tater tots breaking bad none ep...</td>\n",
       "      <td>0.281706</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>[-0.06040393, -0.08328808, -0.06783077, -0.185...</td>\n",
       "      <td>-0.060404</td>\n",
       "      <td>-0.083288</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.185371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048294</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.025297</td>\n",
       "      <td>0.173865</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.066747</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.068452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>145000</td>\n",
       "      <td>friend sister birthday cake doll cake kaise ba...</td>\n",
       "      <td>-0.357064</td>\n",
       "      <td>-0.751194</td>\n",
       "      <td>[0.07443746, -0.050469805, 0.024109313, -0.071...</td>\n",
       "      <td>0.074437</td>\n",
       "      <td>-0.050470</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>-0.071785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.153758</td>\n",
       "      <td>0.169443</td>\n",
       "      <td>0.194380</td>\n",
       "      <td>0.267770</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>-0.101520</td>\n",
       "      <td>-0.016677</td>\n",
       "      <td>0.007512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>10</td>\n",
       "      <td>7960</td>\n",
       "      <td>aaron mercury apaga la luz aaronmercuryapagalu...</td>\n",
       "      <td>-0.365946</td>\n",
       "      <td>-0.788926</td>\n",
       "      <td>[0.051280696, 0.020563934, 0.038841937, -0.050...</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>-0.050469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.045628</td>\n",
       "      <td>0.180763</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>-0.038722</td>\n",
       "      <td>-0.058197</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.023472</td>\n",
       "      <td>-0.066297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>20</td>\n",
       "      <td>934000</td>\n",
       "      <td>sonic amy funny dance sonic amy story shadow j...</td>\n",
       "      <td>-0.305923</td>\n",
       "      <td>-0.563251</td>\n",
       "      <td>[0.028793288, -0.0109023675, 0.028330175, -0.1...</td>\n",
       "      <td>0.028793</td>\n",
       "      <td>-0.010902</td>\n",
       "      <td>0.028330</td>\n",
       "      <td>-0.130150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.202595</td>\n",
       "      <td>0.138078</td>\n",
       "      <td>-0.066435</td>\n",
       "      <td>0.066852</td>\n",
       "      <td>-0.018100</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>-0.061918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>2</td>\n",
       "      <td>12800</td>\n",
       "      <td>check custom skoolie exterior tour travel tour...</td>\n",
       "      <td>-0.365632</td>\n",
       "      <td>-0.787564</td>\n",
       "      <td>[-0.026392385, -0.03499007, -0.026885686, -0.0...</td>\n",
       "      <td>-0.026392</td>\n",
       "      <td>-0.034990</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>-0.089708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>0.029188</td>\n",
       "      <td>0.054394</td>\n",
       "      <td>0.191421</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>-0.052814</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>-0.065704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>22</td>\n",
       "      <td>33100</td>\n",
       "      <td>viral aiya susanti shorts drakodrama lucufunny...</td>\n",
       "      <td>-0.364317</td>\n",
       "      <td>-0.781876</td>\n",
       "      <td>[0.14468384, -0.01698414, 0.108825974, -0.0689...</td>\n",
       "      <td>0.144684</td>\n",
       "      <td>-0.016984</td>\n",
       "      <td>0.108826</td>\n",
       "      <td>-0.068912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208871</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.199137</td>\n",
       "      <td>-0.034939</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>-0.052294</td>\n",
       "      <td>0.032721</td>\n",
       "      <td>-0.053062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>24</td>\n",
       "      <td>18700000</td>\n",
       "      <td>khooni khel cid bengali ep 1307 full episode 1...</td>\n",
       "      <td>0.845612</td>\n",
       "      <td>0.334587</td>\n",
       "      <td>[0.05722373, -0.032237608, 0.020320075, -0.083...</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>-0.032238</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.092815</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.128755</td>\n",
       "      <td>-0.067407</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>-0.021427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4324 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      categoryId   num_sub                                               lang  \\\n",
       "0             24    754000  power book ii ghost official trailer season 3 ...   \n",
       "1             17    314000  julian newman went tristan jass carson roney 2...   \n",
       "2             22   1290000  get ready us go les makeups kb karlas event al...   \n",
       "3             22  10000000  binging babish tater tots breaking bad none ep...   \n",
       "4             26    145000  friend sister birthday cake doll cake kaise ba...   \n",
       "...          ...       ...                                                ...   \n",
       "4319          10      7960  aaron mercury apaga la luz aaronmercuryapagalu...   \n",
       "4320          20    934000  sonic amy funny dance sonic amy story shadow j...   \n",
       "4321           2     12800  check custom skoolie exterior tour travel tour...   \n",
       "4322          22     33100  viral aiya susanti shorts drakodrama lucufunny...   \n",
       "4323          24  18700000  khooni khel cid bengali ep 1307 full episode 1...   \n",
       "\n",
       "      subscribers_normalized  subscribers_boxcox  \\\n",
       "0                  -0.317590           -0.602166   \n",
       "1                  -0.346109           -0.706916   \n",
       "2                  -0.282848           -0.492198   \n",
       "3                   0.281706            0.190738   \n",
       "4                  -0.357064           -0.751194   \n",
       "...                      ...                 ...   \n",
       "4319               -0.365946           -0.788926   \n",
       "4320               -0.305923           -0.563251   \n",
       "4321               -0.365632           -0.787564   \n",
       "4322               -0.364317           -0.781876   \n",
       "4323                0.845612            0.334587   \n",
       "\n",
       "                                        text_embeddings  embedding_0  \\\n",
       "0     [-0.022351101, -0.089554675, -0.072581194, -0....    -0.022351   \n",
       "1     [0.081280485, -0.03597077, 0.07209835, -0.1304...     0.081280   \n",
       "2     [0.036840327, -0.049284644, 0.020821074, -0.14...     0.036840   \n",
       "3     [-0.06040393, -0.08328808, -0.06783077, -0.185...    -0.060404   \n",
       "4     [0.07443746, -0.050469805, 0.024109313, -0.071...     0.074437   \n",
       "...                                                 ...          ...   \n",
       "4319  [0.051280696, 0.020563934, 0.038841937, -0.050...     0.051281   \n",
       "4320  [0.028793288, -0.0109023675, 0.028330175, -0.1...     0.028793   \n",
       "4321  [-0.026392385, -0.03499007, -0.026885686, -0.0...    -0.026392   \n",
       "4322  [0.14468384, -0.01698414, 0.108825974, -0.0689...     0.144684   \n",
       "4323  [0.05722373, -0.032237608, 0.020320075, -0.083...     0.057224   \n",
       "\n",
       "      embedding_1  embedding_2  embedding_3  ...  embedding_90  embedding_91  \\\n",
       "0       -0.089555    -0.072581    -0.092869  ...      0.045912      0.005728   \n",
       "1       -0.035971     0.072098    -0.130494  ...      0.176896      0.136622   \n",
       "2       -0.049285     0.020821    -0.149271  ...      0.125124      0.067622   \n",
       "3       -0.083288    -0.067831    -0.185371  ...      0.048294      0.014508   \n",
       "4       -0.050470     0.024109    -0.071785  ...      0.169739      0.153758   \n",
       "...           ...          ...          ...  ...           ...           ...   \n",
       "4319     0.020564     0.038842    -0.050469  ...      0.065665      0.102974   \n",
       "4320    -0.010902     0.028330    -0.130150  ...      0.121273      0.066571   \n",
       "4321    -0.034990    -0.026886    -0.089708  ...      0.057724      0.029188   \n",
       "4322    -0.016984     0.108826    -0.068912  ...      0.208871      0.132134   \n",
       "4323    -0.032238     0.020320    -0.083689  ...      0.116464      0.092815   \n",
       "\n",
       "      embedding_92  embedding_93  embedding_94  embedding_95  embedding_96  \\\n",
       "0         0.013451      0.214714     -0.019170     -0.099850      0.010372   \n",
       "1         0.047321      0.304242      0.167353     -0.059325      0.007330   \n",
       "2         0.027968      0.188852      0.077738     -0.063245      0.021561   \n",
       "3         0.025297      0.173865     -0.004977     -0.066747      0.046423   \n",
       "4         0.169443      0.194380      0.267770     -0.011082      0.128293   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4319      0.045628      0.180763      0.125266     -0.038722     -0.058197   \n",
       "4320      0.051551      0.202595      0.138078     -0.066435      0.066852   \n",
       "4321      0.054394      0.191421      0.056644     -0.052814      0.023430   \n",
       "4322      0.068627      0.240980      0.199137     -0.034939      0.002377   \n",
       "4323      0.049556      0.236800      0.128755     -0.067407      0.021841   \n",
       "\n",
       "      embedding_97  embedding_98  embedding_99  \n",
       "0         0.050942     -0.056390     -0.057560  \n",
       "1        -0.053111      0.013887     -0.078339  \n",
       "2        -0.019154     -0.028270     -0.073913  \n",
       "3         0.059077     -0.008613     -0.068452  \n",
       "4        -0.101520     -0.016677      0.007512  \n",
       "...            ...           ...           ...  \n",
       "4319      0.000593      0.023472     -0.066297  \n",
       "4320     -0.018100      0.000953     -0.061918  \n",
       "4321      0.025489     -0.002371     -0.065704  \n",
       "4322     -0.052294      0.032721     -0.053062  \n",
       "4323     -0.004865      0.021284     -0.021427  \n",
       "\n",
       "[4324 rows x 106 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = traindf['text_embeddings'].apply(len)\n",
    "\n",
    "plt.hist(lengths, bins=10)\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Length of Text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X.iloc[idx].values, dtype=torch.float), torch.tensor(self.y.iloc[idx], dtype=torch.long)\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_test, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        nn.Sigmoid()\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = 2 \n",
    "model = SimpleNN(input_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.686361530686126\n",
      "Epoch 1, Validation Loss: 0.6827533262617448, Validation Accuracy: 0.522181146025878\n",
      "Epoch 2, Train Loss: 0.6810740385861958\n",
      "Epoch 2, Validation Loss: 0.6815981076044195, Validation Accuracy: 0.522181146025878\n",
      "Epoch 3, Train Loss: 0.6793839230256922\n",
      "Epoch 3, Validation Loss: 0.6809075316962074, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 4, Train Loss: 0.6780876438407337\n",
      "Epoch 4, Validation Loss: 0.68125359100454, Validation Accuracy: 0.522181146025878\n",
      "Epoch 5, Train Loss: 0.6766278664855396\n",
      "Epoch 5, Validation Loss: 0.6801914467531092, Validation Accuracy: 0.5249537892791127\n",
      "Epoch 6, Train Loss: 0.6768606874872657\n",
      "Epoch 6, Validation Loss: 0.6791082550497616, Validation Accuracy: 0.522181146025878\n",
      "Epoch 7, Train Loss: 0.6755479894140187\n",
      "Epoch 7, Validation Loss: 0.6781907239381004, Validation Accuracy: 0.522181146025878\n",
      "Epoch 8, Train Loss: 0.67480479049332\n",
      "Epoch 8, Validation Loss: 0.6779360403032864, Validation Accuracy: 0.5268022181146026\n",
      "Epoch 9, Train Loss: 0.6749104546273456\n",
      "Epoch 9, Validation Loss: 0.677006284980213, Validation Accuracy: 0.5258780036968577\n",
      "Epoch 10, Train Loss: 0.6720824923147174\n",
      "Epoch 10, Validation Loss: 0.6772324022124795, Validation Accuracy: 0.5240295748613678\n",
      "Epoch 11, Train Loss: 0.6727985888719559\n",
      "Epoch 11, Validation Loss: 0.6758737213471356, Validation Accuracy: 0.5249537892791127\n",
      "Epoch 12, Train Loss: 0.6738961926277947\n",
      "Epoch 12, Validation Loss: 0.6783342624411863, Validation Accuracy: 0.522181146025878\n",
      "Epoch 13, Train Loss: 0.6732385741437182\n",
      "Epoch 13, Validation Loss: 0.6751725112690645, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 14, Train Loss: 0.6728928439757403\n",
      "Epoch 14, Validation Loss: 0.675658709862653, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 15, Train Loss: 0.6709825506105143\n",
      "Epoch 15, Validation Loss: 0.6755464602919186, Validation Accuracy: 0.522181146025878\n",
      "Epoch 16, Train Loss: 0.6709530279040337\n",
      "Epoch 16, Validation Loss: 0.6739795663777519, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 17, Train Loss: 0.6715728097102222\n",
      "Epoch 17, Validation Loss: 0.6733483303995693, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 18, Train Loss: 0.6691341264282956\n",
      "Epoch 18, Validation Loss: 0.6728945917942944, Validation Accuracy: 0.5249537892791127\n",
      "Epoch 19, Train Loss: 0.6705362695981475\n",
      "Epoch 19, Validation Loss: 0.6749631131396574, Validation Accuracy: 0.5240295748613678\n",
      "Epoch 20, Train Loss: 0.6671722505022498\n",
      "Epoch 20, Validation Loss: 0.6727162284009597, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 21, Train Loss: 0.6670485436916351\n",
      "Epoch 21, Validation Loss: 0.6735292094595292, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 22, Train Loss: 0.665200275971609\n",
      "Epoch 22, Validation Loss: 0.6712043776231653, Validation Accuracy: 0.5268022181146026\n",
      "Epoch 23, Train Loss: 0.6657700429067892\n",
      "Epoch 23, Validation Loss: 0.6725382086108712, Validation Accuracy: 0.5212569316081331\n",
      "Epoch 24, Train Loss: 0.6645534130580285\n",
      "Epoch 24, Validation Loss: 0.6717745363712311, Validation Accuracy: 0.5258780036968577\n",
      "Epoch 25, Train Loss: 0.6643793876556789\n",
      "Epoch 25, Validation Loss: 0.6746910775409025, Validation Accuracy: 0.522181146025878\n",
      "Epoch 26, Train Loss: 0.6628224525381538\n",
      "Epoch 26, Validation Loss: 0.6749850529081681, Validation Accuracy: 0.5231053604436229\n",
      "Epoch 27, Train Loss: 0.6625803424155011\n",
      "Epoch 27, Validation Loss: 0.663885830079808, Validation Accuracy: 0.6025878003696857\n",
      "Epoch 28, Train Loss: 0.6609043292701244\n",
      "Epoch 28, Validation Loss: 0.6733533529674306, Validation Accuracy: 0.5268022181146026\n",
      "Epoch 29, Train Loss: 0.6611799470642034\n",
      "Epoch 29, Validation Loss: 0.6716988735339221, Validation Accuracy: 0.5258780036968577\n",
      "Epoch 30, Train Loss: 0.661481574177742\n",
      "Epoch 30, Validation Loss: 0.6748320109703961, Validation Accuracy: 0.5277264325323475\n",
      "Epoch 31, Train Loss: 0.660517143414301\n",
      "Epoch 31, Validation Loss: 0.6694341319448808, Validation Accuracy: 0.5268022181146026\n",
      "Epoch 32, Train Loss: 0.6588209337171387\n",
      "Epoch 32, Validation Loss: 0.6711796241648057, Validation Accuracy: 0.5268022181146026\n",
      "Epoch 33, Train Loss: 0.6593706739299438\n",
      "Epoch 33, Validation Loss: 0.6733611646820518, Validation Accuracy: 0.5249537892791127\n",
      "Epoch 34, Train Loss: 0.6588019119466052\n",
      "Epoch 34, Validation Loss: 0.6764295171288883, Validation Accuracy: 0.5194085027726433\n",
      "Epoch 35, Train Loss: 0.6573582935859176\n",
      "Epoch 35, Validation Loss: 0.6717655553537256, Validation Accuracy: 0.5249537892791127\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "num_epochs = 35\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss / len(val_dataloader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a29500abb6bdb3556fdfc455803f9bb3348bbc89ce500f32511904c582090f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
